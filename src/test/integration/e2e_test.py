# Copyright IBM Corp. 2017 All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

import csv
import docker
import json
import logging
import matplotlib.pyplot as plt
import os
import random
import sys
import time
import threading
import trustas
import unittest

# config logger before importing other dependencies
CREATE_LOGS = True
LOG_FILE = "logs/main.log"
logging.basicConfig(
    level=logging.INFO, filename=LOG_FILE if CREATE_LOGS else "")
logger = logging.getLogger(__name__)

from test.integration.utils import BaseTestCase, cli_call, mkdir_p

# =========

# execution
DEFAULT_SLEEP   = 5
LOCAL_DEPLOY    = False
KEEP_NETWORK    = False
WIPE_ALL        = False
EXP_DIR         = "experiments"

# chaincode
CC_PATH     = 'github.com/example_cc'
CC_NAME     = 'example_cc'
CC_VERSION  = '1.0'

# network
ORGS_LIST           = []    # list of orgs populated automagically
NUM_ORGS            = 5     # size of real network (# of peers) -- affects ledger size and net traffic
NUM_SIMULATED_ORGS  = 100   # size of simulated network (for agreements creation) -- no effect on metrics
NUM_AGREEMENTS      = 100   # total number of agreements simulated
ENCRYPTION          = True  # if True, enables encrypted output
MPA                 = 1     # number of measurements per agreement simulated

HELP_MSG = """
    Usage: tox -- test/integration/e2e_test.py [ARG_STRING]

    ARG_STRING: Single string (no spaces) with multiple arguments with the format:

        -[PROP 1]=[VAL 1]-[PROP NO-VAL]-[PROP 3]=[VAL 3]...

        "PROP X" may be:
            peers       Number of peers in the network [1, 200]. Can be quite resource intensive if >30.
            agreements  Number of agreements to be simulated.
            unsafe      Encrypted output is disabled. Takes no value.

        Examples:
            tox -- test/integration/e2e_test.py -agreements=100-unsafe-peers=20
            tox -- test/integration/e2e_test.py -peers=15-agreements=500
"""


def trustas_start():
    """Entry point for TrustAS experiments."""

    # set parameters passed as CLI arguments
    get_params_from_cli()

    # craft configuration files from the global parameters set
    create_config_files()


def create_config_files():
    """Generate Docker Compose YAML and JSON configuration files."""

    global ORGS_LIST
    ORGS_LIST = ["org" + str(orgNum) + ".example.com" for orgNum in range(1, NUM_ORGS+1)]
    PORT_INCREMENT  = True  # True for localhost deployments
    orderer_name    = "orderer.example.com"
    orderer_host    = "localhost"
    org_host        = "localhost"
    orderer_port    = 7050
    base_port       = 7051

    WORKING_DIR = "test/fixtures/"
    with open(os.path.join(WORKING_DIR, "trustas-base.json"), "r") as fp:
        net_stats = json.load(fp)
    docker_net = """
# ::: WARNING ::: This file is automatically generated by TrustAS. Any modifications will be overwritten.\n\n
version: '2'  # v3 does not support 'extends' yet
services:\n
    """

    # GENERATE ORDERER JSON

    orderer_dir = os.path.join(WORKING_DIR, "trustas/crypto-config/ordererOrganizations/example.com")
    orderer_msp_dir = os.path.join(orderer_dir, "users/Admin@example.com/msp")
    sk_ord, _, _ = cli_call(["ls", os.path.join(orderer_msp_dir, "keystore")])
    sk_ord = sk_ord.decode().split()[0]
    # orderer organization
    orderer_org = {
        "mspid": "OrdererMSP",
        "orderers": [orderer_name],
        "certificateAuthorities": ["ca-orderer"],
        "users": {
            "Admin": {
                "cert":         os.path.join(orderer_msp_dir, "signcerts/Admin@example.com-cert.pem"),
                "private_key":  os.path.join(orderer_msp_dir, "keystore", sk_ord)
            }
        }
    }
    # orderer description
    orderer_desc = {
        "url": orderer_host + ":" + str(orderer_port),
        "grpcOptions": {
            "ssl-target-name-override": orderer_name,
            "grpc-max-send-message-length": 15
        },
        "tlsCACerts": {
            "path": os.path.join(orderer_dir, "tlsca/tlsca.example.com-cert.pem")
        }
    }
    # add orderers to base config
    net_stats["organizations"][orderer_name]    = orderer_org
    net_stats["orderers"][orderer_name]         = orderer_desc

    # GENERATE ORDERER IN DOCKER COMPOSE

    docker_net = docker_net + """orderer.example.com:\n
        extends:
            file: orderer-base.yaml
            service: orderer-base
        container_name: orderer.example.com
        hostname: orderer.example.com
        ports:
            - \"""" + str(orderer_port) + """:""" + str(orderer_port) + """"
        volumes:
            - ./trustas/channel-artifacts/orderer.genesis.block:/var/hyperledger/orderer/orderer.genesis.block
            - ./trustas/crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp
            - ./trustas/crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/:/var/hyperledger/orderer/tls
        command: orderer start
    """

    for org in range(1, NUM_ORGS + 1):

        # org properties
        org_name        = ORGS_LIST[org-1]
        org_msp_id      = "Org" + str(org) + "MSP"
        peer_name       = "peer0." + org_name
        ca_name         = "ca-org" + str(org)

        # directories
        users_dir   = os.path.join(WORKING_DIR, "trustas/crypto-config/peerOrganizations", org_name, "users")
        peers_dir   = os.path.join(WORKING_DIR, "trustas/crypto-config/peerOrganizations", org_name, "peers")
        msp_adm_dir = os.path.join(users_dir, "Admin@" + org_name, "msp")
        msp_usr_dir = os.path.join(users_dir, "User1@" + org_name, "msp")

        # get private key file names
        sk_adm, _, _ = cli_call(["ls", os.path.join(msp_adm_dir, "keystore")])
        sk_usr, _, _ = cli_call(["ls", os.path.join(msp_usr_dir, "keystore")])
        sk_adm = sk_adm.decode().split()[0]
        sk_usr = sk_usr.decode().split()[0]

        # GENERATE ORG
        org_desc = {
            "mspid": org_msp_id,
            "peers": [peer_name],
            "certificateAuthorities": [ca_name],
            "users": {
                "Admin": {
                    "cert":        os.path.join(msp_adm_dir, "signcerts/Admin@" + org_name + "-cert.pem"),
                    "private_key": os.path.join(msp_adm_dir, "keystore", sk_adm)
                },
                "User1": {
                    "cert":        os.path.join(msp_usr_dir, "signcerts/User1@" + org_name + "-cert.pem"),
                    "private_key": os.path.join(msp_usr_dir, "keystore", sk_usr)
                }
            }
        }

        # GENERATE PEER
        peer_desc = {
            "url":      org_host + ":" + str(base_port),     # :7051
            "eventUrl": org_host + ":" + str(base_port + 2), # :7053
            "grpcOptions": {
                "ssl-target-name-override": peer_name,
                "grpc.http2.keepalive_time": 15
            },
            "tlsCACerts": {
                "path": os.path.join(peers_dir, peer_name, "msp/tlscacerts", "tlsca." + org_name + "-cert.pem")
            }
        }

        # GENERATE CA
        ca_desc = {
            "url": "https://" + org_host + ":" + str(base_port + 3), # :7054
            "grpcOptions": {
                "verify": True
            },
            "tlsCACerts": {
                "path":
                "test/fixtures/trustas/crypto-config/peerOrganizations/" + org_name + "/ca/ca." + org_name + "-cert.pem"
            },
            "registrar": [{
                "enrollId": "admin",
                "enrollSecret": "adminpw"
            }]
        }

        # add orgs to base config
        net_stats["organizations"][org_name]            = org_desc
        net_stats["peers"][peer_name]                   = peer_desc
        net_stats["certificateAuthorities"][ca_name]    = ca_desc

        # GENERATE DOCKER COMPOSE ENTRY

        docker_net = docker_net + """\n\n    """ + peer_name + """:\n
        extends:
            file: peer-base.yaml
            service: peer-base
        container_name: """ + peer_name + """
        hostname: """ + peer_name + """
        environment:
            - CORE_PEER_ID=""" + peer_name + """
            - CORE_PEER_ADDRESS=""" + peer_name + """:7051
            - CORE_PEER_GOSSIP_EXTERNALENDPOINT=""" + peer_name + """:7051
            - CORE_PEER_CHAINCODELISTENADDRESS=""" + peer_name + """:7052
            - CORE_PEER_GOSSIP_BOOTSTRAP=""" + peer_name + """:7051
            - CORE_PEER_LOCALMSPID=""" + org_msp_id + """
        volumes:
            - ./trustas/crypto-config/peerOrganizations/""" + org_name + """/peers/""" + peer_name + """/msp:/etc/hyperledger/fabric/msp
            - ./trustas/crypto-config/peerOrganizations/""" + org_name + """/peers/""" + peer_name + """/tls:/etc/hyperledger/fabric/tls
        ports:
            - """ + str(base_port) + """:7051
            - """ + str(base_port + 1) + """:7052
            - """ + str(base_port + 2) + """:7053
        command: peer node start
        """

        # increment base_port to avoid conflicts in local deploys
        if PORT_INCREMENT:
            base_port = base_port + 100

    # SAVE TO FILES
    # json
    with open(os.path.join(WORKING_DIR, "trustas-net.json"), "w") as fp:
        json.dump(net_stats, fp)

    # docker compose
    with open(os.path.join(WORKING_DIR, "dc-trustas.yaml"), "w") as fp:
        fp.write(docker_net)


class E2eTest(BaseTestCase):

    def setUp(self):
        cleanup_script = "/home/lucas/work/pg/trustas/src/cleanup.sh"
        trustas_start()                 # generate all configuration files required and set global parameters
        self.orgs = ORGS_LIST           # update list of organizations
        cli_call([cleanup_script])      # clean docker assets before initializing the network
        super(E2eTest, self).setUp()    # initialize network

    def tearDown(self):
        super(E2eTest, self).tearDown()

    def channel_create(self):
        """Creates a channel (does not join peers to it)."""

        # By default, self.user is the admin of org1
        response = self.client.channel_create('orderer.example.com',
                                              self.channel_name,
                                              self.user,
                                              self.config_yaml,
                                              self.channel_profile)
        self.assertTrue(response)

        logger.info("E2E: Channel creation done: name={}".format(
            self.channel_name))

    def channel_join(self):
        """Join peers in all orgs into an existing channel"""

        # channel must already exist when to join
        channel = self.client.get_channel(self.channel_name)
        self.assertIsNotNone(channel)

        orgs = self.orgs
        for org in orgs:
            org_admin   = self.client.get_user(org, 'Admin')
            response    = self.client.channel_join(
                requestor       = org_admin,
                channel_name    = self.channel_name,
                peer_names      = ['peer0.' + org],
                orderer_name    = 'orderer.example.com'
            )
            self.assertTrue(response)
            # Verify the ledger exists now in the peer node
            dc = docker.from_env()
            for peer in ['peer0']:
                peer0_container = dc.containers.get(peer + '.' + org)
                code, output = peer0_container.exec_run(
                    'test -f '
                    '/var/hyperledger/production/ledgersData/chains/chains/{}'
                    '/blockfile_000000'.format(self.channel_name))
                self.assertEqual(code, 0, "Local ledger not exists")

        logger.info("E2E: Channel join done: name={}".format(
            self.channel_name))


    def chaincode_install(self):
        """Installs chaincode to peers"""

        orgs = self.orgs
        for org in orgs:
            org_admin   = self.client.get_user(org, "Admin")
            response    = self.client.chaincode_install(
                requestor   = org_admin,
                peer_names  = ['peer0.' + org],
                cc_path     = CC_PATH,
                cc_name     = CC_NAME,
                cc_version  = CC_VERSION
            )
            self.assertTrue(response)
            # Verify the cc pack exists now in the peer node
            dc = docker.from_env()
            for peer in ['peer0']:
                peer0_container = dc.containers.get(peer + '.' + org)
                code, output = peer0_container.exec_run(
                    'test -f '
                    '/var/hyperledger/production/chaincodes/example_cc.1.0')
                self.assertEqual(code, 0, "chaincodes pack not exists")

        logger.info("E2E: chaincode install done")


    def chaincode_instantiate(self):
        """Test chaincode instantiation to peer"""

        orgs = [self.orgs[0]]
        args = ['a', '200', 'b', '300']
        for org in orgs:
            org_admin   = self.client.get_user(org, "Admin")
            response    = self.client.chaincode_instantiate(
                requestor       = org_admin,
                channel_name    = self.channel_name,
                peer_names      = ['peer0.' + org],
                args            = args,
                cc_name         = CC_NAME,
                cc_version      = CC_VERSION
            )
            logger.info(
                "E2E: Chaincode instantiation response {}".format(response))
            self.assertTrue(response)

        logger.info("E2E: chaincode instantiation done")

    def chaincode_invoke(self, args):
        """Invokes chaincode with arguments
        Args:
            args: list of arguments to be passed to chaincode function
        """
        logger.info("Invoke: " + args[0])

        orgs = [self.orgs[0]]
        for org in orgs:
            org_admin   = self.client.get_user(org, "Admin")
            response    = self.client.chaincode_invoke(
                requestor       = org_admin,
                channel_name    = self.channel_name,
                peer_names      = ['peer0.' + org],
                args            = args,
                cc_name         = CC_NAME,
                cc_version      = CC_VERSION
            )
            self.assertTrue(response)

    def __craft_settings(self):
        """Set interconnection settings"""

        mode = "ciphertext" if ENCRYPTION else "plaintext"
        path = os.path.join("storage", mode, "{}_{}_{}".format(
            NUM_ORGS, NUM_AGREEMENTS, MPA), str(time.time()))

        return {
            "encryption":       ENCRYPTION,         # storage encryption (True / False)
            "experiment_path":  path,               # path for the experiment's results
            "peers_real":       NUM_ORGS,           # number of peers in the IXP
            "peers_sim":        NUM_SIMULATED_ORGS, # number of simulated ASes in the IXP
            "connections":      NUM_AGREEMENTS,     # total number of pair interconnections / agreements in the network
            "mpa":              MPA,                # number of measurements simulated per agreement
            "storage":          "json"
        }

    def __cc_ops(self):
        """A sequence of chaincode operations simulating agreements"""

        step_ledger_size = 0    # Period of ledger size measurements.
        # i.e. it is the number of agreements transacted between two ledger size measurements.
        # If 0, the ledger size monitoring is disabled and measurement happens only after the last transaction.

        exp_settings = self.__craft_settings()  # create settings
        agreements = trustas.experiments.exp_privacy_cost(
            **exp_settings)  # simulate agreements

        # create agreement entries in the ledger
        print(" > Saving agreements to the ledger")
        data_x, data_y = self.__save_agreements(
            agreements,
            encryption=exp_settings["encryption"],
            step_ledger_size=step_ledger_size)

        # save storage data to files
        print(" > Saving statistics")
        save_data(
            data_x,
            data_y,
            file="size_creation",
            title="Ledger growth on agreements creation ({} ASes)".format(
                exp_settings["peers_real"]),
            path=exp_settings["experiment_path"],
            xlabel="Number of agreements published",
            ylabel="Blockchain size (KB)")

        # create measurement entries in the ledger
        print(" > Saving measurements to the ledger")
        data_x, data_y = self.__save_measurements(
            agreements,
            encryption=exp_settings["encryption"],
            step_ledger_size=step_ledger_size)

        # save storage data to files
        print(" > Saving statistics")
        save_data(
            data_x,
            data_y,
            file="size_measurements",
            title="Ledger growth on measurements publishing ({} ASes, {} MPA)".format(
                exp_settings["peers_real"],
                exp_settings["mpa"]),
            path=exp_settings["experiment_path"],
            xlabel="Number of measurements published",
            ylabel="Blockchain size (KB)")

        # query a random agreement
        # time.sleep(DEFAULT_SLEEP)
        # args = [str(random.choice(agreements).id)]
        # res = self.__cc_call('queryAgreement', args=args, prop_type=CC_QUERY)
        # logger.info("Query Result: %s", json.dumps(res).encode('utf-8'))

    def __store_in_ledger(self, args, parallel=True):
        """Invoke chaincode in a separate thread.
        Args:
            args:       List of arguments for the chaincode call
            parallel:   Enables asynchronous execution (with a deliberate sleep, see below)
        Returns:
            Thread which executed the invocation method.
            If parallel is False, the thread will have already finished executing when returned.
        """

        # store to the ledger in the background
        thread = threading.Thread(target=self.chaincode_invoke, args=([args]))
        thread.daemon = True        # daemon this thread
        thread.start()              # start the execution
        if parallel:
            # local executions with many (tens or hundreds) threads show transaction losses
            # the following sleep is to treat this issue and is proportional to the network size
            time.sleep(NUM_ORGS / 50)
        if not parallel:
            # wait for thread response
            thread.join()
        return thread

    def __save_measurements(self,
                            agreements,
                            encryption=True,
                            step_ledger_size=10):
        """Save measurements in agreements to the ledger"""

        data_x = []
        data_y = []
        threads = []        # list of threads
        parallel = True     # parallelize execution
        for idx, ag in enumerate(agreements):
            metrics = ag.get_encrypted_metrics(
            ) if encryption else ag.get_plaintext_metrics()
            for idxm, m in enumerate(metrics):
                args = [
                    str(ag.id),  # agreement ID
                    str(ag.id) + str(idxm),  # measurement ID
                    json.dumps(m)  # single set of metrics
                ]

                threads.append(self.__store_in_ledger(args, parallel=parallel))

            # every few agreements, measure the blockchain
            if step_ledger_size > 0 and (idx + 1) % step_ledger_size == 0:
                # wait for pending transactions
                for t in threads:
                    t.join()
                data_x.append(idx + 1)
                data_y.append(measure_blockchain_size())

        for t in threads:
            t.join()
        time.sleep(DEFAULT_SLEEP)
        data_x.append(len(agreements))
        data_y.append(measure_blockchain_size())

        return data_x, data_y


    def __save_agreements(self,
                          agreements,
                          encryption=True,
                          step_ledger_size=10):
        """Save agreements to the ledger"""

        data_x = []
        data_y = []
        threads = []        # list of threads
        parallel = True     # parallelize execution
        for idx, ag in enumerate(agreements):
            peers = ag.peers
            sla = json.dumps(ag.get_encrypted_sla() if encryption else ag.
                             get_plaintext_sla())
            args = [
                str(ag.id),  # agreement ID
                str(peers[0]),  # peer A
                str(peers[1]),  # peer B
                sla  # agreement SLA
            ]

            threads.append(self.__store_in_ledger(args, parallel=parallel))

            # every few agreements, measure the blockchain
            if step_ledger_size > 0 and (idx + 1) % step_ledger_size == 0:
                # wait for pending transactions
                for t in threads:
                    t.join()
                data_x.append(idx + 1)
                data_y.append(measure_blockchain_size())

        # for t in threads:
        #     t.join()
        # time.sleep(DEFAULT_SLEEP)
        # data_x.append(len(agreements))
        # data_y.append(measure_blockchain_size())

        return data_x, data_y


    def test_in_sequence(self):

        logger.info("\n\nE2E testing started...")

        self.channel_create()
        time.sleep(5)  # wait for channel created

        print("CHECKPOINT ALPHA")

        self.channel_join()
        self.chaincode_install()
        self.chaincode_instantiate()

        print("CHECKPOINT BETA")

        self.__cc_ops()  # run chaincode operations

        # trustas.experiments.exp_package_demos()

        print("CHECKPOINT GAMMA")

        logger.info("E2E all test cases done\n\n")


def save_data(x, y, path, file, title='', clabel='', xlabel='', ylabel='', legend=''):
    """ Saves generated data (plot + csv) to path.
        SVG is generated only with two or more points (length of x).

    Args:
        x:          X axis data.
        y:          Y axis data.
        path:       part of output dir: [EXP_DIR] / [path]
        file:       filenames (no extension) used for svg and csv output.
        title:      title of plot.
        clabel:      curve label.
        xlabel:     X axis label.
        ylabel:     Y axis label.
        legend:     plot legend.
    Returns:
        None (only outputs files).
    """

    assert (len(x) == len(y))   # lengths of x and y must match

    working_dir = os.path.join(EXP_DIR, path)
    mkdir_p(working_dir)
    svg_filepath = os.path.join(working_dir, file + ".svg")
    csv_filepath = os.path.join(working_dir, file + ".csv")

    # if there is more than one point, plot results to SVG file
    if len(x) > 1:
        plt.clf()   # clear old plots
        plt.plot(x, y, label=clabel)
        plt.xlabel(xlabel)
        plt.ylabel(ylabel)
        plt.title(title)
        plt.legend(legend)
        plt.savefig(svg_filepath)

    # build csv and save
    rows = zip(x, y)
    with open(csv_filepath, 'w+', newline='') as csvfile:
        spamwriter = csv.writer(csvfile, quoting=csv.QUOTE_MINIMAL)
        spamwriter.writerow([xlabel, ylabel])
        for r in rows:
            spamwriter.writerow(r)


def measure_blockchain_size(peer="peer0.org1.example.com"):
    """Measures blockchain size through a command line call to a container.

    Args:
        peer:   The container name (also full peer name) to consult.
    Returns:
        Integer representing the current ledger size in KB (1024B) on disk.
    """

    output, error, _ = cli_call([
        "docker", "exec", "-it", peer, "du",
        "/var/hyperledger/production/ledgersData/chains/chains/businesschannel"
    ])
    if error:
        return None
    try:
        size = output.decode("utf-8").split()[0]
        size = int(size)
        return size
    except:
        return None


if __name__ == "__main__":
    unittest.main()

def get_params_from_cli():

    global NUM_ORGS
    global ENCRYPTION
    global NUM_AGREEMENTS

    # if argument -pXX is passed, override the number of peers
    argv = os.sys.argv[-2]
    argv = argv.split('-')
    for p in argv:
        v = p.split("=")
        if len(v[0]) == 0:
            continue
        elif v[0] == "help":
            print(HELP_MSG)
        elif v[0] == "unsafe":
            ENCRYPTION = False
        elif v[0] == "agreements":
            try:
                NUM_AGREEMENTS = int(v[1])
            except:
                raise ValueError("Failed to convert argument 'agreements'")
        elif v[0] == "peers":
            try:
                NUM_ORGS = int(v[1])
            except:
                raise ValueError("Failed to convert argument 'peers'")
        else:
            raise ValueError("TrustAS: unknown option '{}'\n\n{}".format(v[0], HELP_MSG))

    print("\n ::: STARTING TRUSTAS :::")
    print(" > Peers:         {}".format(NUM_ORGS))
    print(" > Agreements:    {}".format(NUM_AGREEMENTS))
    print(" > Encryption:    {}".format("ENABLED" if ENCRYPTION else "DISABLED"))
